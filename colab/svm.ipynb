{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["I50SSG91edA9"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Import thư viện và load dữ liệu"],"metadata":{"id":"V2BB2iXOpWw_"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import re\n","import nltk\n","import string\n","import time\n","nltk.download('stopwords')\n","nltk.download('punkt_tab')\n","from nltk.corpus import stopwords\n","from nltk.stem.porter import PorterStemmer\n","from nltk.tokenize import word_tokenize\n","from sklearn.feature_extraction.text import TfidfVectorizer, HashingVectorizer\n","from sklearn.model_selection import train_test_split\n","from bs4 import BeautifulSoup\n","from sklearn.metrics import confusion_matrix,f1_score, precision_score,recall_score,classification_report\n","from google.colab import drive\n","from sklearn.feature_selection import SelectKBest, chi2\n","from sklearn.svm import SVC\n","from sklearn.metrics import accuracy_score\n","from scipy.sparse import csr_matrix"],"metadata":{"id":"aYzv7FNziRij","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1745021377352,"user_tz":-420,"elapsed":13976,"user":{"displayName":"Duong Vu COng","userId":"01870437980576342211"}},"outputId":"e229aae0-69ce-4fdf-e965-a6352645c08e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"]}]},{"cell_type":"code","source":["# df = pd.read_csv(\"https://media.githubusercontent.com/media/PTIT-Projects/ttcs-svm-spam-email/refs/heads/main/dataset/combined_data.csv\")\n","df = pd.read_csv(\"https://media.githubusercontent.com/media/PTIT-Projects/ttcs-svm-spam-email/refs/heads/main/dataset/sampled_dataset1000.csv\")"],"metadata":{"id":"5O2jlz-Qn12H","collapsed":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Tiền xử lý dữ liệu\n"],"metadata":{"id":"Y1QXz7bnpTxO"}},{"cell_type":"code","source":["\n","# viet thuong\n","df['text'] = df['text'].str.lower()\n","\n","# xoa ky tu khong phai ASCII\n","df['text'] = df['text'].apply(lambda x: re.sub(r'[^\\x00-\\x7F]+', '', x) if isinstance(x, str) else x)\n","\n","# xoa khoang trang\n","df['text'] = df['text'].apply(lambda x: re.sub(r'^\\s+|\\s+$', '', x).strip() if isinstance(x, str) else x)\n","\n","# xoa html, xml\n","def remove_html_xml(text):\n","    try:\n","        soup = BeautifulSoup(text, 'html.parser')\n","        return soup.get_text()\n","    except:\n","        return text\n","\n","df['text'] = df['text'].apply(remove_html_xml)\n","\n","# xoa ky tu dac biet\n","def remove_special_characters(word):\n","    return word.translate(str.maketrans('', '', string.punctuation))\n","\n","df['text'] = df['text'].apply(remove_special_characters)\n","\n","# xoa url\n","def remove_urls(text):\n","    return re.sub(r'http\\S+|www\\S+|\\S+\\.(com|net|org|edu|gov|mil|int|info|biz|co)\\S+', '', text)\n","\n","df['text'] = df['text'].apply(remove_urls)\n","\n","# xoa dia chi email\n","def remove_emails(text):\n","    return re.sub(r'\\S+@\\S+', '', text)\n","\n","df['text'] = df['text'].apply(remove_emails)\n","\n","# tach thanh cac tu\n","df['text'] = df['text'].apply(word_tokenize)\n","\n","# xoa tu dung(tieng anh)\n","ENGLISH_STOP_WORDS = set(stopwords.words('english'))\n","\n","def remove_stop_words(words):\n","    return [word for word in words if word not in ENGLISH_STOP_WORDS]\n","\n","df['text'] = df['text'].apply(remove_stop_words)\n","\n","# cat goc tu\n","stemmer = PorterStemmer()\n","\n","def stem_words(words):\n","    return [stemmer.stem(word) for word in words]\n","\n","df['text'] = df['text'].apply(stem_words)\n","\n","# noi cac tu thanh chuoi\n","df['text'] = df['text'].apply(' '.join)\n","\n","# dataset trainning voi test\n","X = df['text']\n","y = df['label']\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n","\n","# tfidf\n","vectorizer = TfidfVectorizer()\n","X_train_tfidf = vectorizer.fit_transform(X_train)\n","X_test_tfidf = vectorizer.transform(X_test)\n","\n","\n","\n"],"metadata":{"id":"eUitz0y9o1eF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# hashing_vectorizer\n","hashing_vectorizer = HashingVectorizer(n_features=3000)\n","X_train_hashed = hashing_vectorizer.fit_transform(X_train)\n","X_test_hashed = hashing_vectorizer.transform(X_test)\n"],"metadata":{"id":"3FKY-qx8BBCP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(X_train_hashed.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KEpqkwFgEmhY","executionInfo":{"status":"ok","timestamp":1744980337838,"user_tz":-420,"elapsed":4,"user":{"displayName":"B22DCKH008_Trương Quốc Bình","userId":"04203996072274535246"}},"outputId":"14e8a96c-c136-41a4-861f-48a5f881f986"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(800, 3000)\n"]}]},{"cell_type":"markdown","source":["# SVM"],"metadata":{"id":"QZXtfe1lgzWo"}},{"cell_type":"markdown","source":["## Linear Hard Margin SVM"],"metadata":{"id":"QXiXY_AsrrBR"}},{"cell_type":"code","source":["class HardMarginSVM:\n","    \"\"\"\n","    Optimized Hard Margin SVM implementation using gradient descent\n","\n","    Attributes\n","    -------------\n","    eta : float\n","        Learning rate\n","    epoch : int\n","        Number of epochs\n","    random_state : int\n","        Random seed\n","    is_trained : bool\n","        Training completion flag\n","    num_samples : int\n","        Number of training samples\n","    num_features : int\n","        Number of features\n","    w : NDArray[float]\n","        Parameter vector: (num_features, ) ndarray\n","    b : float\n","        Bias parameter\n","    alpha : NDArray[float]\n","        Lagrange multipliers: (num_samples, ) ndarray\n","    \"\"\"\n","    def __init__(self, eta=0.001, epoch=1000, random_state=42):\n","        self.eta = eta\n","        self.epoch = epoch\n","        self.random_state = random_state\n","        self.is_trained = False\n","        self.support_vectors = None\n","\n","    def fit(self, X, y):\n","        \"\"\"\n","        Fit parameter vector to training data\n","\n","        Parameters\n","        --------------\n","        X : NDArray[NDArray[float]]\n","            Training data: (num_samples, num_features) matrix\n","        y : NDArray[float]\n","            Training labels: (num_samples) ndarray\n","        \"\"\"\n","        # Convert sparse matrix to dense if needed\n","        if hasattr(X, \"toarray\"):\n","            X = X.toarray()\n","\n","        self.num_samples = X.shape[0]\n","        self.num_features = X.shape[1]\n","\n","        y_unique = np.unique(y)\n","        if len(y_unique) != 2:\n","            raise ValueError(\"Binary classification requires exactly 2 classes\")\n","\n","        if set(y_unique) == {0, 1}:\n","            y = np.where(y == 0, -1, 1)\n","\n","        self.w = np.zeros(self.num_features)\n","        self.b = 0\n","\n","\n","        rgen = np.random.RandomState(self.random_state)\n","        self.alpha = rgen.uniform(low=0.0, high=0.01, size=self.num_samples)\n","        for i in range(self.epoch):\n","            self._cycle(X, y)\n","\n","        sv_indices = np.where(self.alpha != 0)[0]\n","\n","        self.support_vectors = sv_indices\n","\n","        self.w = np.zeros(self.num_features)\n","        for i in sv_indices:\n","            self.w += self.alpha[i] * y[i] * X[i]\n","\n","        bias_sum = 0\n","        for i in sv_indices:\n","            bias_sum += y[i] - np.dot(self.w, X[i])\n","\n","        self.b = bias_sum / len(sv_indices)\n","\n","        self.is_trained = True\n","        return self\n","\n","    def predict(self, X):\n","        \"\"\"\n","        Return predictions\n","\n","        Parameters\n","        --------------\n","        X : NDArray[NDArray[float]]\n","            Data to classify: (any, num_features) matrix\n","\n","        Returns\n","        ----------\n","        result : NDArray[int]\n","            Classification results 0 or 1: (any, ) ndarray\n","        \"\"\"\n","        if not self.is_trained:\n","            raise Exception('Model not trained yet')\n","\n","        # Convert sparse matrix to dense if needed\n","        if hasattr(X, \"toarray\"):\n","            X = X.toarray()\n","\n","        decision_values = X @ self.w + self.b\n","\n","        result = np.where(decision_values >= 0, 1, 0)\n","        return result\n","\n","    def _cycle(self, X, y):\n","        \"\"\"\n","        One gradient descent cycle\n","\n","        Parameters\n","        --------------\n","        X : NDArray[NDArray[float]]\n","            Training data: (num_samples, num_features) matrix\n","        y : NDArray[float]\n","            Training labels: (num_samples) ndarray\n","        \"\"\"\n","        y = y.reshape([-1, 1]) #(n,1)\n","\n","        XXT = X @ X.T\n","        H = (y @ y.T) * XXT\n","\n","        grad = np.ones(self.num_samples) - H @ self.alpha\n","\n","        self.alpha += self.eta * grad\n","\n","        self.alpha = np.clip(self.alpha, 0, None)\n"],"metadata":{"id":"s6p8sbAQruJy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Linear Hard Margin SVM cải tiến V1\n"],"metadata":{"id":"QnNQAY0imfbn"}},{"cell_type":"code","source":["class HardMarginSVMV1:\n","    \"\"\"\n","    Optimized Hard Margin SVM implementation using gradient descent\n","\n","    Attributes\n","    -------------\n","    eta : float\n","        Learning rate\n","    epoch : int\n","        Number of epochs\n","    random_state : int\n","        Random seed\n","    is_trained : bool\n","        Training completion flag\n","    num_samples : int\n","        Number of training samples\n","    num_features : int\n","        Number of features\n","    w : NDArray[float]\n","        Parameter vector: (num_features, ) ndarray\n","    b : float\n","        Bias parameter\n","    alpha : NDArray[float]\n","        Lagrange multipliers: (num_samples, ) ndarray\n","    \"\"\"\n","    def __init__(self, eta=0.001, epoch=1000, random_state=42, convergence_tol=1e-4):\n","        self.eta = eta\n","        self.epoch = epoch\n","        self.random_state = random_state\n","        self.convergence_tol = convergence_tol\n","        self.is_trained = False\n","        self.support_vectors = None\n","\n","    def fit(self, X, y):\n","        \"\"\"\n","        Fit parameter vector to training data\n","\n","        Parameters\n","        --------------\n","        X : NDArray[NDArray[float]]\n","            Training data: (num_samples, num_features) matrix\n","        y : NDArray[float]\n","            Training labels: (num_samples) ndarray\n","        \"\"\"\n","        # Convert sparse matrix to dense if needed\n","        if hasattr(X, \"toarray\"):\n","            X = X.toarray()\n","        self.num_samples = X.shape[0]\n","        self.num_features = X.shape[1]\n","\n","        y_unique = np.unique(y)\n","        if len(y_unique) != 2:\n","            raise ValueError(\"Binary classification requires exactly 2 classes\")\n","\n","        if set(y_unique) == {0, 1}:\n","            y = np.where(y == 0, -1, 1)\n","\n","        self.w = np.zeros(self.num_features)\n","        self.b = 0\n","\n","\n","        rgen = np.random.RandomState(self.random_state)\n","        self.alpha = rgen.uniform(low=0.0, high=0.01, size=self.num_samples)\n","        prev_alpha = np.zeros(self.num_samples)\n","        for i in range(self.epoch):\n","            np.copyto(prev_alpha, self.alpha)\n","\n","            self._cycle(X, y)\n","\n","            if i % 10 == 0:\n","                delta = np.linalg.norm(self.alpha - prev_alpha)\n","                if delta < self.convergence_tol:\n","                    break\n","\n","        sv_indices = np.where(self.alpha != 0)[0]\n","\n","        self.support_vectors = sv_indices\n","\n","        self.w = np.zeros(self.num_features)\n","        for i in sv_indices:\n","            self.w += self.alpha[i] * y[i] * X[i]\n","\n","        bias_sum = 0\n","        for i in sv_indices:\n","            bias_sum += y[i] - np.dot(self.w, X[i])\n","\n","        self.b = bias_sum / len(sv_indices)\n","\n","        self.is_trained = True\n","        return self\n","\n","    def predict(self, X):\n","        \"\"\"\n","        Return predictions\n","\n","        Parameters\n","        --------------\n","        X : NDArray[NDArray[float]]\n","            Data to classify: (any, num_features) matrix\n","\n","        Returns\n","        ----------\n","        result : NDArray[int]\n","            Classification results 0 or 1: (any, ) ndarray\n","        \"\"\"\n","        if not self.is_trained:\n","            raise Exception('Model not trained yet')\n","        # Convert sparse matrix to dense if needed\n","        if hasattr(X, \"toarray\"):\n","            X = X.toarray()\n","\n","        decision_values = X @ self.w + self.b\n","\n","        result = np.where(decision_values >= 0, 1, 0)\n","        return result\n","\n","    def _cycle(self, X, y):\n","        \"\"\"\n","        One gradient descent cycle\n","\n","        Parameters\n","        --------------\n","        X : NDArray[NDArray[float]]\n","            Training data: (num_samples, num_features) matrix\n","        y : NDArray[float]\n","            Training labels: (num_samples) ndarray\n","        \"\"\"\n","        y = y.reshape([-1, 1])\n","\n","        XXT = X @ X.T\n","        H = (y @ y.T) * XXT\n","\n","        grad = np.ones(self.num_samples) - H @ self.alpha\n","\n","        self.alpha += self.eta * grad\n","\n","        self.alpha = np.clip(self.alpha, 0, None)"],"metadata":{"id":"FiPl_LdumhYo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Linear Soft Margin SVM"],"metadata":{"id":"I50SSG91edA9"}},{"cell_type":"code","source":["import numpy as np\n","\n","class LinearSVM:\n","    def __init__(self, C=1.0, max_iter=1000, lr=0.001, tolerance=1e-5):\n","        self.C = C\n","        self.max_iter = max_iter\n","        self.lr = lr\n","        self.tolerance = tolerance\n","        self.w = None\n","        self.b = 0\n","\n","    def fit(self, X, y):\n","        # Convert labels to -1, 1 if they're 0, 1\n","        y_binary = np.where(y <= 0, -1, 1)\n","\n","        n_samples, n_features = X.shape\n","\n","        self.w = np.zeros(n_features)\n","\n","        alpha = np.zeros(n_samples)\n","\n","        # Pre-compute Gram matrix to avoid recalculation in the loop\n","        # K[i,j] = y_i * y_j * (x_i · x_j)\n","        K = np.dot(X, X.T) * np.outer(y_binary, y_binary)\n","\n","        # SGD optimization\n","        for iteration in range(self.max_iter):\n","            alpha_prev = alpha.copy()\n","\n","            # Vectorized margin calculation\n","            margins = 1 - K.dot(alpha)\n","\n","            # Update all alphas in one step\n","            mask = margins > 0\n","            alpha[mask] += self.lr * margins[mask]\n","\n","            # Apply box constraint\n","            alpha = np.clip(alpha, 0, self.C)\n","\n","            # Check convergence\n","            if np.max(np.abs(alpha - alpha_prev)) < self.tolerance:\n","                break\n","\n","        # Calculate weights\n","        self.w = np.dot(X.T, alpha * y_binary)\n","\n","        # Calculate bias using support vectors\n","        sv_indices = alpha > 1e-5\n","        if np.any(sv_indices):\n","            self.b = np.mean(y_binary[sv_indices] - np.dot(X[sv_indices], self.w))\n","\n","    def predict(self, X):\n","        \"\"\"Predict class labels for samples in X.\"\"\"\n","        return np.where(np.dot(X, self.w) + self.b >= 0, 1, 0)\n","\n","    def get_parameters(self):\n","      print(f'w: {self.w}')\n","      print(f'b: {self.b}')\n","\n","    def decision_function(self, X):\n","        \"\"\"Return distance of samples to the decision boundary.\"\"\"\n","        return np.dot(X, self.w) + self.b"],"metadata":{"id":"dFoqhUJn7jlA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## SVM tối ưu sử dụng thuật toán Pegasos"],"metadata":{"id":"Tc9IaxlvdrX2"}},{"cell_type":"code","source":["class SVM:\n","    def __init__(self, lambda_param=1e-4, epoch=1000, batch_size=256, tol=1e-4, random_state=42):\n","        self.lambda_param = lambda_param\n","        self.epoch = epoch\n","        self.batch_size = batch_size\n","        self.tol = tol\n","        self.random_state = random_state\n","        self.is_trained = False\n","\n","    def fit(self, X, y):\n","        if hasattr(X, \"toarray\"):\n","            X = csr_matrix(X)\n","\n","        self.num_samples, self.num_features = X.shape\n","\n","        y_unique = np.unique(y)\n","        if len(y_unique) != 2:\n","            raise ValueError(\"Phân loại nhị phân cần 2 nhãn\")\n","        if set(y_unique) == {0, 1}:\n","            y = np.where(y == 0, -1, 1)\n","\n","        self.w = np.zeros(self.num_features, dtype=np.float32)\n","        self.b = 0.0\n","\n","        np.random.seed(self.random_state)\n","        t = 0\n","        previous_objective = float(\"inf\")\n","\n","        for ep in range(1, self.epoch + 1):\n","            indices = np.random.permutation(self.num_samples)\n","            for start in range(0, self.num_samples, self.batch_size):\n","                t += 1\n","                end = start + self.batch_size\n","                batch_idx = indices[start:end]\n","                X_batch = X[batch_idx]\n","                y_batch = y[batch_idx]\n","\n","                eta = 1.0 / (self.lambda_param * t)\n","                margins = y_batch * (X_batch.dot(self.w) + self.b)\n","                mask = margins < 1\n","                self.w *= (1 - eta * self.lambda_param)\n","                if np.any(mask):\n","                    X_violate = X_batch[mask]\n","                    y_violate = y_batch[mask]\n","                    self.w += (eta / self.batch_size) * np.dot(y_violate, X_violate.toarray() if hasattr(X_violate, \"toarray\") else X_violate)\n","                    self.b += (eta / self.batch_size) * np.sum(y_violate)\n","                norm_w = np.linalg.norm(self.w)\n","                factor = min(1, (1.0 / np.sqrt(self.lambda_param)) / (norm_w))\n","                self.w *= factor\n","\n","            decision = X.dot(self.w) + self.b\n","            hinge_losses = np.maximum(0, 1 - y * decision)\n","            objective = 0.5 * self.lambda_param * np.dot(self.w, self.w) + np.mean(hinge_losses)\n","\n","            if ep % 10 == 0:\n","                print(f\"Epoch {ep}, Giá trị hàm mục tiêu: {objective:.4f}\")\n","\n","            if abs(previous_objective - objective) < self.tol:\n","                print(f\"Dừng sớm tại epoch {ep}, giá trị hàm mục tiêu thay đổi: {abs(previous_objective - objective):.6f}\")\n","                break\n","            previous_objective = objective\n","\n","        self.is_trained = True\n","        return self\n","\n","    def predict(self, X):\n","        if not self.is_trained:\n","            raise Exception(\"Mô hình chưa được huấn luỵen\")\n","\n","        if hasattr(X, \"toarray\"):\n","            X = csr_matrix(X)\n","\n","        decision = X.dot(self.w) + self.b\n","        return np.where(decision >= 0, 1, 0)"],"metadata":{"id":"oqer70Xddu83"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Train model và dự đoán"],"metadata":{"id":"RIh4ESwhg4Cl"}},{"cell_type":"code","source":["X_train_dense = X_train_tfidf.toarray()\n","X_test_dense = X_test_tfidf.toarray()\n","\n"],"metadata":{"id":"Qwc8fspzN1yB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Linear SVM Hard Margin ban đầu"],"metadata":{"id":"nzTcvAdsoH9M"}},{"cell_type":"code","source":["hard_margin_svm = HardMarginSVM()\n","hard_margin_svm.fit(X_train_dense, y_train.to_numpy())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l4jfIdy3oMiC","executionInfo":{"status":"ok","timestamp":1744980736681,"user_tz":-420,"elapsed":381725,"user":{"displayName":"B22DCKH008_Trương Quốc Bình","userId":"04203996072274535246"}},"outputId":"4560b4e7-1da2-4c04-c07f-6fa6816d1c5e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<__main__.HardMarginSVM at 0x7d99f1048a10>"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":["y_pred = hard_margin_svm.predict(X_test_dense)\n","print(classification_report(y_test, y_pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QUzHg6YiN9qO","executionInfo":{"status":"ok","timestamp":1744980736690,"user_tz":-420,"elapsed":44,"user":{"displayName":"B22DCKH008_Trương Quốc Bình","userId":"04203996072274535246"}},"outputId":"802dbcdc-ebf3-4906-f7c1-4c063431df8d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.96      0.93      0.94        98\n","           1       0.93      0.96      0.95       102\n","\n","    accuracy                           0.94       200\n","   macro avg       0.95      0.94      0.94       200\n","weighted avg       0.95      0.94      0.94       200\n","\n"]}]},{"cell_type":"code","source":["print(confusion_matrix(y_test, y_pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yjSV8JBxOGdv","executionInfo":{"status":"ok","timestamp":1744980736691,"user_tz":-420,"elapsed":20,"user":{"displayName":"B22DCKH008_Trương Quốc Bình","userId":"04203996072274535246"}},"outputId":"8c1adf97-7d4a-4064-c2cb-cd146c59f3b7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[91  7]\n"," [ 4 98]]\n"]}]},{"cell_type":"markdown","source":["### Thử với hashing vectorizer\n"],"metadata":{"id":"hw27wVirKS5U"}},{"cell_type":"code","source":["linear_svm = HardMarginSVM()\n","linear_svm.fit(X_train_hashed, y_train.to_numpy())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FWOJ5F9DtE9G","executionInfo":{"status":"ok","timestamp":1744980819540,"user_tz":-420,"elapsed":82848,"user":{"displayName":"B22DCKH008_Trương Quốc Bình","userId":"04203996072274535246"}},"outputId":"1319bb29-fb21-4412-d9e2-46d3bd3157be"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<__main__.HardMarginSVM at 0x7d99f14fd6d0>"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["y_pred = linear_svm.predict(X_test_hashed)\n","print(classification_report(y_test, y_pred))\n","print(confusion_matrix(y_test, y_pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wl8IL7UoA5mz","executionInfo":{"status":"ok","timestamp":1744980819541,"user_tz":-420,"elapsed":13,"user":{"displayName":"B22DCKH008_Trương Quốc Bình","userId":"04203996072274535246"}},"outputId":"06624765-0231-4cb4-a0e3-ebdab53c753d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.92      0.88      0.90        98\n","           1       0.89      0.93      0.91       102\n","\n","    accuracy                           0.91       200\n","   macro avg       0.91      0.90      0.90       200\n","weighted avg       0.91      0.91      0.90       200\n","\n","[[86 12]\n"," [ 7 95]]\n"]}]},{"cell_type":"markdown","source":["## Linear SVM Hard Margin cải tiến V1"],"metadata":{"id":"n3z1KESgoVhl"}},{"cell_type":"code","source":["hard_margin_svm_v1 = HardMarginSVMV1()\n","hard_margin_svm_v1.fit(X_train_dense, y_train.to_numpy())"],"metadata":{"id":"mx6ne1pFOJW2","colab":{"base_uri":"https://localhost:8080/","height":304},"executionInfo":{"status":"error","timestamp":1744980230183,"user_tz":-420,"elapsed":221668,"user":{"displayName":"B22DCKH008_Trương Quốc Bình","userId":"04203996072274535246"}},"outputId":"ffcbc870-9124-4533-ebc7-72884ed71ae8"},"execution_count":null,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-0b20c6adff4a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mhard_margin_svm_v1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHardMarginSVMV1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhard_margin_svm_v1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_dense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-10-5bd66b7a4720>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-10-5bd66b7a4720>\u001b[0m in \u001b[0;36m_cycle\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0mH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mXXT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mH\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meta\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/_core/numeric.py\u001b[0m in \u001b[0;36mones\u001b[0;34m(shape, dtype, order, device, like)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mset_array_function_like_doc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mset_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'numpy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlike\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["y_pred = hard_margin_svm_v1.predict(X_test_dense)\n","print(classification_report(y_test, y_pred))\n","print(confusion_matrix(y_test, y_pred))"],"metadata":{"id":"7tI8Zo41odOG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Linear SVM Soft Margin"],"metadata":{"id":"HcubRJorektO"}},{"cell_type":"code","source":["linear_svm = LinearSVM()\n","linear_svm.fit(X_train_dense, y_train.to_numpy())\n","y_pred = linear_svm.predict(X_test_dense)\n","print(classification_report(y_test, y_pred))\n","print(confusion_matrix(y_test, y_pred))"],"metadata":{"id":"t3Dc9Mb0A4rb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(linear_svm.get_parameters())"],"metadata":{"id":"X1lAjV7P_YRL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["linear_svm = LinearSVM()\n","linear_svm.fit(X_train_hashed, y_train.to_numpy())\n","y_pred = linear_svm.predict(X_test_hashed)\n","print(classification_report(y_test, y_pred))\n","print(confusion_matrix(y_test, y_pred))"],"metadata":{"id":"4Nt2lSWxQcW_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Áp dụng feature extraction và so sánh"],"metadata":{"id":"1bZLmoQ9Xb2L"}},{"cell_type":"markdown","source":["## Khi không sử dụng feature extraction"],"metadata":{"id":"ZPo07ByLXmmU"}},{"cell_type":"code","source":["\n","pegasos = SVM()\n","\n","start = time.time()\n","pegasos.fit(X_train_tfidf, y_train.to_numpy())\n","end = time.time()\n","\n","y_pred_pegasos = pegasos.predict(X_test_tfidf)\n","\n","\n","print(\"Thời gian huấn luyện (Pegasos):\", end - start, \"giây\")\n","print(\"Accuracy (Pegasos):\", accuracy_score(y_test, y_pred_pegasos))\n","print(\"F1-score (Pegasos):\", f1_score(y_test, y_pred_pegasos))\n","\n","hard_svm = HardMarginSVMV1()\n","\n","start = time.time()\n","hard_svm.fit(X_train_tfidf, y_train)\n","end = time.time()\n","\n","y_pred_hard = hard_svm.predict(X_test_tfidf)\n","\n","print(\"Thời gian huấn luyện (Hard-margin v1):\", end - start, \"giây\")\n","print(\"Accuracy (Hard-margin v1):\", accuracy_score(y_test, y_pred_hard))\n","print(\"F1-score (Hard-margin v1):\", f1_score(y_test, y_pred_hard))\n","\n"],"metadata":{"executionInfo":{"status":"ok","timestamp":1744983230881,"user_tz":-420,"elapsed":395203,"user":{"displayName":"B22DCKH008_Trương Quốc Bình","userId":"04203996072274535246"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"11e9193a-160f-492c-9158-c5a0f6c72aab","id":"PqOFFk_K51x2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 10, Giá trị hàm mục tiêu: 32.6296\n","Epoch 20, Giá trị hàm mục tiêu: 1.1482\n","Epoch 30, Giá trị hàm mục tiêu: 1.6400\n","Epoch 40, Giá trị hàm mục tiêu: 1.4125\n","Epoch 50, Giá trị hàm mục tiêu: 0.4692\n","Epoch 60, Giá trị hàm mục tiêu: 0.3155\n","Epoch 70, Giá trị hàm mục tiêu: 0.2233\n","Epoch 80, Giá trị hàm mục tiêu: 0.2225\n","Epoch 90, Giá trị hàm mục tiêu: 0.1400\n","Epoch 100, Giá trị hàm mục tiêu: 0.6319\n","Epoch 110, Giá trị hàm mục tiêu: 0.1472\n","Epoch 120, Giá trị hàm mục tiêu: 0.1190\n","Epoch 130, Giá trị hàm mục tiêu: 0.1022\n","Epoch 140, Giá trị hàm mục tiêu: 0.0883\n","Epoch 150, Giá trị hàm mục tiêu: 0.0779\n","Epoch 160, Giá trị hàm mục tiêu: 0.1303\n","Epoch 170, Giá trị hàm mục tiêu: 0.0809\n","Epoch 180, Giá trị hàm mục tiêu: 0.0704\n","Epoch 190, Giá trị hàm mục tiêu: 0.1427\n","Epoch 200, Giá trị hàm mục tiêu: 0.0667\n","Epoch 210, Giá trị hàm mục tiêu: 0.0611\n","Epoch 220, Giá trị hàm mục tiêu: 0.0556\n","Epoch 230, Giá trị hàm mục tiêu: 0.5965\n","Epoch 240, Giá trị hàm mục tiêu: 0.0570\n","Epoch 250, Giá trị hàm mục tiêu: 0.0526\n","Epoch 260, Giá trị hàm mục tiêu: 0.0491\n","Dừng sớm tại epoch 262, giá trị hàm mục tiêu thay đổi: 0.000012\n","Thời gian huấn luyện (Pegasos): 3.459212303161621 giây\n","Accuracy (Pegasos): 0.93\n","F1-score (Pegasos): 0.9326923076923077\n","Thời gian huấn luyện (Hard-margin v1): 391.6063678264618 giây\n","Accuracy (Hard-margin v1): 0.945\n","F1-score (Hard-margin v1): 0.9468599033816425\n"]}]},{"cell_type":"markdown","source":["## Khi sử dụng feature extraction"],"metadata":{"id":"4eEnFg5DXuAZ"}},{"cell_type":"markdown","source":["### k = 5000"],"metadata":{"id":"JhMyBe8JZg7C"}},{"cell_type":"code","source":["selector = SelectKBest(score_func  = chi2, k =5000)\n","selector.fit(X_train_tfidf, y_train)\n","X_train_reduced = selector.transform(X_train_tfidf)\n","X_test_reduced = selector.transform(X_test_tfidf)\n","print(f'X_train_reduced shape: {X_train_reduced.shape}')\n","print(f'X_train_tfidf shape: {X_train_tfidf.shape}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-Ojxd-04Xx3b","executionInfo":{"status":"ok","timestamp":1745021482133,"user_tz":-420,"elapsed":48,"user":{"displayName":"Duong Vu COng","userId":"01870437980576342211"}},"outputId":"ca1fc951-588a-4b4a-cbc0-f7e662f801bf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["X_train_reduced shape: (800, 5000)\n","X_train_tfidf shape: (800, 15517)\n"]}]},{"cell_type":"code","source":["\n","pegasos = SVM()\n","\n","start = time.time()\n","pegasos.fit(X_train_reduced, y_train.to_numpy())\n","end = time.time()\n","\n","y_pred_pegasos = pegasos.predict(X_test_reduced)\n","\n","\n","print(\"Thời gian huấn luyện (Pegasos):\", end - start, \"giây\")\n","print(\"Accuracy (Pegasos):\", accuracy_score(y_test, y_pred_pegasos))\n","print(\"F1-score (Pegasos):\", f1_score(y_test, y_pred_pegasos))\n","\n","hard_svm = HardMarginSVMV1()\n","\n","start = time.time()\n","hard_svm.fit(X_train_reduced, y_train)\n","end = time.time()\n","\n","y_pred_hard = hard_svm.predict(X_test_reduced)\n","\n","print(\"Thời gian huấn luyện (Hard-margin v1):\", end - start, \"giây\")\n","print(\"Accuracy (Hard-margin v1):\", accuracy_score(y_test, y_pred_hard))\n","print(\"F1-score (Hard-margin v1):\", f1_score(y_test, y_pred_hard))\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6npb0sXLXw-M","executionInfo":{"status":"ok","timestamp":1745021693262,"user_tz":-420,"elapsed":156883,"user":{"displayName":"Duong Vu COng","userId":"01870437980576342211"}},"outputId":"4908678c-f75e-47d3-d6aa-1b32771b10cd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 10, Giá trị hàm mục tiêu: 15.4006\n","Epoch 20, Giá trị hàm mục tiêu: 0.7687\n","Epoch 30, Giá trị hàm mục tiêu: 6.2444\n","Epoch 40, Giá trị hàm mục tiêu: 4.8203\n","Epoch 50, Giá trị hàm mục tiêu: 0.4487\n","Epoch 60, Giá trị hàm mục tiêu: 0.2938\n","Epoch 70, Giá trị hàm mục tiêu: 0.3182\n","Epoch 80, Giá trị hàm mục tiêu: 0.2201\n","Epoch 90, Giá trị hàm mục tiêu: 0.1757\n","Epoch 100, Giá trị hàm mục tiêu: 0.1468\n","Epoch 110, Giá trị hàm mục tiêu: 0.1228\n","Epoch 120, Giá trị hàm mục tiêu: 0.3925\n","Epoch 130, Giá trị hàm mục tiêu: 0.1167\n","Epoch 140, Giá trị hàm mục tiêu: 0.1003\n","Epoch 150, Giá trị hàm mục tiêu: 0.1120\n","Epoch 160, Giá trị hàm mục tiêu: 0.0943\n","Epoch 170, Giá trị hàm mục tiêu: 0.0937\n","Epoch 180, Giá trị hàm mục tiêu: 0.0800\n","Epoch 190, Giá trị hàm mục tiêu: 0.0727\n","Epoch 200, Giá trị hàm mục tiêu: 0.0762\n","Epoch 210, Giá trị hàm mục tiêu: 0.0694\n","Dừng sớm tại epoch 210, giá trị hàm mục tiêu thay đổi: 0.000055\n","Thời gian huấn luyện (Pegasos): 1.9836857318878174 giây\n","Accuracy (Pegasos): 0.925\n","F1-score (Pegasos): 0.9295774647887324\n","Thời gian huấn luyện (Hard-margin v1): 154.78433346748352 giây\n","Accuracy (Hard-margin v1): 0.93\n","F1-score (Hard-margin v1): 0.9326923076923077\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"Fke5woEOY4dV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### k = 10000"],"metadata":{"id":"ODYB2SNWZkKf"}},{"cell_type":"code","source":["selector = SelectKBest(score_func  = chi2, k =10000)\n","selector.fit(X_train_tfidf, y_train)\n","X_train_reduced = selector.transform(X_train_tfidf)\n","X_test_reduced = selector.transform(X_test_tfidf)\n","print(f'X_train_reduced shape: {X_train_reduced.shape}')\n","print(f'X_train_tfidf shape: {X_train_tfidf.shape}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1745021799784,"user_tz":-420,"elapsed":27,"user":{"displayName":"Duong Vu COng","userId":"01870437980576342211"}},"outputId":"6ad27273-26d9-42c6-d8d8-8a9e2911f44b","id":"lVTJp3diZkKg"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["X_train_reduced shape: (800, 10000)\n","X_train_tfidf shape: (800, 15517)\n"]}]},{"cell_type":"code","source":["\n","pegasos = SVM()\n","\n","start = time.time()\n","pegasos.fit(X_train_reduced, y_train.to_numpy())\n","end = time.time()\n","\n","y_pred_pegasos = pegasos.predict(X_test_reduced)\n","\n","\n","print(\"Thời gian huấn luyện (Pegasos):\", end - start, \"giây\")\n","print(\"Accuracy (Pegasos):\", accuracy_score(y_test, y_pred_pegasos))\n","print(\"F1-score (Pegasos):\", f1_score(y_test, y_pred_pegasos))\n","\n","hard_svm = HardMarginSVMV1()\n","\n","start = time.time()\n","hard_svm.fit(X_train_reduced, y_train)\n","end = time.time()\n","\n","y_pred_hard = hard_svm.predict(X_test_reduced)\n","\n","print(\"Thời gian huấn luyện (Hard-margin v1):\", end - start, \"giây\")\n","print(\"Accuracy (Hard-margin v1):\", accuracy_score(y_test, y_pred_hard))\n","print(\"F1-score (Hard-margin v1):\", f1_score(y_test, y_pred_hard))\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1745022091387,"user_tz":-420,"elapsed":288529,"user":{"displayName":"Duong Vu COng","userId":"01870437980576342211"}},"outputId":"abc80d49-dfaa-41ab-d523-07e75d449091","id":"O5OXEPDLZkKg"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 10, Giá trị hàm mục tiêu: 17.9088\n","Epoch 20, Giá trị hàm mục tiêu: 1.4727\n","Epoch 30, Giá trị hàm mục tiêu: 6.8120\n","Epoch 40, Giá trị hàm mục tiêu: 3.4568\n","Epoch 50, Giá trị hàm mục tiêu: 0.4446\n","Epoch 60, Giá trị hàm mục tiêu: 0.2895\n","Epoch 70, Giá trị hàm mục tiêu: 0.2126\n","Epoch 80, Giá trị hàm mục tiêu: 1.1532\n","Epoch 90, Giá trị hàm mục tiêu: 0.1964\n","Epoch 100, Giá trị hàm mục tiêu: 0.1579\n","Epoch 110, Giá trị hàm mục tiêu: 0.1328\n","Epoch 120, Giá trị hàm mục tiêu: 0.1307\n","Epoch 130, Giá trị hàm mục tiêu: 0.1110\n","Epoch 140, Giá trị hàm mục tiêu: 0.0958\n","Epoch 150, Giá trị hàm mục tiêu: 0.0850\n","Epoch 160, Giá trị hàm mục tiêu: 0.0746\n","Epoch 170, Giá trị hàm mục tiêu: 0.0893\n","Epoch 180, Giá trị hàm mục tiêu: 0.0756\n","Epoch 190, Giá trị hàm mục tiêu: 0.1257\n","Epoch 200, Giá trị hàm mục tiêu: 0.0685\n","Epoch 210, Giá trị hàm mục tiêu: 0.0786\n","Epoch 220, Giá trị hàm mục tiêu: 0.0582\n","Epoch 230, Giá trị hàm mục tiêu: 0.1271\n","Epoch 240, Giá trị hàm mục tiêu: 0.0636\n","Dừng sớm tại epoch 249, giá trị hàm mục tiêu thay đổi: 0.000039\n","Thời gian huấn luyện (Pegasos): 1.4250621795654297 giây\n","Accuracy (Pegasos): 0.92\n","F1-score (Pegasos): 0.9259259259259259\n","Thời gian huấn luyện (Hard-margin v1): 287.028892993927 giây\n","Accuracy (Hard-margin v1): 0.94\n","F1-score (Hard-margin v1): 0.9423076923076923\n"]}]},{"cell_type":"markdown","source":["### Nhận xét\n","Khi sử dụng feature extraction thì số chiều của dữ liệu giảm, chạy nhanh hơn tuy nhiên thì độ chính xác cũng như f1 score giảm. Do bản thân thuật toán Pegasos cho SVM chạy tương đối nhanh và không tốn quá nhiều bộ nhớ nên nhóm tập trung vào độ chính xác và f1 score cho mô hình. Do đó nhóm em không áp dụng feature extraction cho bộ dữ liệu gốc"],"metadata":{"id":"iHE2gU5abGIq"}},{"cell_type":"code","source":[],"metadata":{"id":"HSFSKLgQZkKh"},"execution_count":null,"outputs":[]}]}